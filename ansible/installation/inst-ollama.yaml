---
- name: Install Ollama Linux Machine
  hosts: "{{ hostname | default('all') }}" 
  become: true
  tasks:

    - name: Check if Ollama is already installed
      stat:
        path: /usr/local/bin/ollama  # Or wherever ollama is installed
      register: ollama_installed

    - name: Install Ollama if not installed or if update is desired
      block:
        - name: Download and install Ollama
          shell: "curl -fsSL https://ollama.com/install.sh | sh"
          args:
            executable: /bin/bash # explicitly set the shell for the pipe to work
          register: ollama_install_output
          # Check for errors during installation
          failed_when: ollama_install_output.rc != 0
          # Optionally print the output for debugging
          when: ollama_installed.stat.exists == false or update_ollama is defined

        - name: Ensure ollama group exists (important for persistent data)
          group:
            name: ollama
            state: present
            system: yes
            
        - name: Add user to ollama group (if needed, replace with the user you want to use)
          user:
            name: ollama  # Or a specific user if needed
            groups: ollama
            append: yes

        - name: Create .ollama directory for persistent data (if it doesn't exist)
          file:
            path: /home/ollama/.ollama  # Or another suitable location
            state: directory
            owner: ollama
            group: ollama
            mode: 0755
            recurse: yes  # Needed if creating subdirectories later
      when: not ollama_installed.stat.exists or update_ollama is defined # Only run if not installed or update is requested

    - name: Pull the latest Ollama image (using async for long-running task)
      block:
        - name: Pull latest image
          async: 3600
          poll: 0
          command: "ollama pull llama3.2:latest"
          register: pull_result
          args:
            chdir: /home/ollama
            executable: /bin/bash
          ignore_errors: true # Allow the task to continue even if the pull fails

        - name: Check if pull_result is defined (crucial check)
          set_fact:
            pull_result_defined: "{{ pull_result is defined }}"

        - name: Check pull status (optional - useful in AWX/Tower)
          block:
            - name: Get pull status
              async_status:
                jid: "{{ pull_result.job }}"
              register: pull_status
              until: pull_status.finished
              retries: 360
              delay: 10

            - debug:
                msg: "Pull status: {{ pull_status }}"

            - name: Fail if the image pull failed
              assert:
                that:
                  - pull_status.result.rc == 0
                  - pull_status.result is defined
                  - pull_status.result.stderr is not defined
                msg: "Image pull failed: {{ pull_status.result.stderr | default('No error message') }}"
          when: pull_result_defined and pull_result.job is defined # Double conditional check

      become: false
      run_once: true

    - name: Run the Ollama image in the background
      block:
        - name: Run Ollama (background process)
          shell: "ollama run llama3.2:latest > /dev/null 2>&1 &"  # Redirect output and run in background
          args:
            chdir: "/home/ollama"
            executable: /bin/bash
          register: ollama_run_result

        - name: Wait a short time for Ollama to start (adjust as needed)
          pause:
            seconds: 5

        - name: Check if Ollama is running (optional)
          shell: "pgrep ollama" # Or a more specific check
          register: ollama_running
          ignore_errors: true #Don't fail if not found

        - debug:
            msg: "Ollama running check: {{ ollama_running.stdout }}"

        - name: Assert Ollama is running
          assert:
            that:
              - ollama_running.rc == 0
            msg: "Ollama did not seem to start correctly. pgrep output: {{ ollama_running.stdout }}"

      become: false
      run_once: true